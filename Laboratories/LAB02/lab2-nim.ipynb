{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 2: Evolutionary Strategies\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None, last_move: Nimply = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "        self.last_move = last_move\n",
    "\n",
    "    def __bool__(self):\n",
    "        return bool(sum(self._rows) > 0)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        self.last_move = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n",
    "\n",
    "    def n_possible_moves(self) -> int:\n",
    "        return sum(self._rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional method is considered, `expert_system`, because the `optimal` method don't exploit the late game strategy, reason why it doesn't always win even against `random` or `gabriele`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_system(state: Nim) -> Nimply:\n",
    "    \"\"\"\n",
    "    Details on https://en.wikipedia.org/wiki/Nim#Proof_of_the_winning_formula.\n",
    "    \"\"\"\n",
    "    analysis = analize(state)\n",
    "    rows_not_zero = len(state.rows) - state.rows.count(0)\n",
    "    # case of one single row with lenght >= 2\n",
    "    if state.rows.count(1) == (rows_not_zero - 1):\n",
    "        row, num_objects = [(row, num_objects) for row, num_objects in enumerate(state.rows) if num_objects > 1][0]\n",
    "        if (rows_not_zero % 2) == 1:\n",
    "            num_objects = num_objects if (num_objects - 1) <= len(state.rows) else len(state.rows)\n",
    "            return Nimply(row, num_objects - 1)\n",
    "        else:\n",
    "            num_objects = num_objects if num_objects <= len(state.rows) else len(state.rows)\n",
    "            return Nimply(row, num_objects)\n",
    "    # case with more row with length >= 2\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns == 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = [move for move in list(analysis[\"possible_moves\"].keys())]\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests of proposed methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(strategy):\n",
    "    won = 0\n",
    "    for _ in range(100):\n",
    "        nim = Nim(5)\n",
    "        player = 0\n",
    "        while nim:\n",
    "            ply = strategy[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 0:\n",
    "            won += 1\n",
    "    return won/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert vs random:  1.0\n",
      "Expert vs gabriele:  1.0\n",
      "Expert vs optimal:  1.0\n",
      "Optimal vs random:  0.75\n",
      "Optimal vs gabriele:  0.82\n",
      "Random vs gabriele:  0.72\n"
     ]
    }
   ],
   "source": [
    "strategy = (expert_system, pure_random)\n",
    "print(\"Expert vs random: \", play(strategy))\n",
    "strategy = (expert_system, gabriele)\n",
    "print(\"Expert vs gabriele: \", play(strategy))\n",
    "strategy = (expert_system, optimal)\n",
    "print(\"Expert vs optimal: \", play(strategy))\n",
    "strategy = (optimal, pure_random)\n",
    "print(\"Optimal vs random: \", play(strategy))\n",
    "strategy = (optimal, gabriele)\n",
    "print(\"Optimal vs gabriele: \", play(strategy))\n",
    "strategy = (pure_random, gabriele)\n",
    "print(\"Random vs gabriele: \", play(strategy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different solutions were developed for this lab:\n",
    "\n",
    "The first solution implements, as requested, an evolutionary algorithm. \n",
    "\n",
    "The second solution instead is based on a MonteCarlo-style algorithm, which we felt could be applied very well to this type of problem, having few 'legal' moves available and not knowing the game principles behind Nim making it difficult to create a suitable fitness function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Evolutionary Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing the evolutionary strategy was not easy, considering the fact that we had to write functions that, given a state of the board, would perform a certain well-defined move. Having no knowledge of the game and how to evaluate a board state, some sub-optimal functions were written to test the evolutionary method anyway. \n",
    "\n",
    "Various methods are considered within the evolutionary strategy, in particular: \n",
    "\n",
    "* `lowest_available`: the stick from the row where there are least available is taken. \n",
    "\n",
    "* `mirror_move`: mirrors the opponent's last move. \n",
    "\n",
    "* `greedy_move`: Pick the move that minimises the number of sticks in the heap.\n",
    "\n",
    "* `gabriele`, `optimal`, `expert_system`: Already described before.\n",
    "\n",
    "Three of these proposed methods are selected within an evolutionary strategy. The game state is divided into three different phases, ealry-game, mid-game and late-game, depending on how many sticks are left in the heap compared to how many we had at the beginning of the game. For each of these phases, we evaluated the probability with which each of the three methods is selected through the evolutionary strategy. \n",
    "\n",
    "Considering the non-optimality of the methods proposed by us, we wanted to try to include `optimal` and `expert_system` among the possible methods, imagining that our genetic strategy will always choose the latter two as they are the ones that ensure victory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moves_ratio(nim: Nim) -> float:\n",
    "    \"\"\"\n",
    "    Compute a value [0, 1] to estimate the phase of the match computing the ratio between possible moves and total moves.\n",
    "    \"\"\"\n",
    "    # total possible moves\n",
    "    possible_moves = sum([1 for _, c in enumerate(nim.rows) for _ in range(1, min(c + 1, len(nim.rows)))])\n",
    "    initial_nim = Nim(len(nim.rows))\n",
    "    # total moves in the start game\n",
    "    total_moves = sum([1 for _, c in enumerate(initial_nim.rows) for _ in range(1, min(c + 1, len(initial_nim.rows)))])\n",
    "\n",
    "    return possible_moves / total_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_available(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick the lowest available move in a sequential manner.\"\"\"\n",
    "    for row, count in enumerate(state.rows):\n",
    "        if count > 0:\n",
    "            return Nimply(row, 1)\n",
    "    # If all rows are empty, play a random move\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*random.choice(possible_moves))\n",
    "\n",
    "def mirror_move(state: Nim) -> Nimply:\n",
    "    \"\"\"Mirror the opponent's last move.\"\"\"\n",
    "    if state.last_move is not None:\n",
    "        row, count = state.last_move\n",
    "        max_count = state.rows[row]\n",
    "        mirrored_count = max_count - count + 1\n",
    "        return Nimply(row, mirrored_count)\n",
    "    else:\n",
    "        # If it's the first move, play randomly\n",
    "        possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "        return Nimply(*random.choice(possible_moves))\n",
    "    \n",
    "def greedy_move(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick the move that minimizes the number of sticks in the heap\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*min(possible_moves, key=lambda m: sum(state.rows) - m[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGIES = [lowest_available, greedy_move, gabriele]\n",
    "mutation_rate: float = (0.01, 0.1)\n",
    "\n",
    "class Individual:\n",
    "    n_strategy: int\n",
    "    phase_thresholds: list[float]\n",
    "    strategy_probs: list[list[float]]\n",
    "\n",
    "    def __init__(self, n_strategy: int = None, strategy_probs = None, phase_thresholds = None) -> None:\n",
    "        if n_strategy is None:\n",
    "            n_strategy = len(STRATEGIES)\n",
    "        if phase_thresholds is None:\n",
    "            phase_thresholds = sorted([random.random(), random.random()])\n",
    "        else:\n",
    "            phase_thresholds = sorted([max(0, phase_thresholds[0]), min(1, phase_thresholds[1])])\n",
    "        if strategy_probs is None:\n",
    "            strategy_probs = np.random.rand(len(phase_thresholds) + 1, n_strategy)\n",
    "        # n possible strategies\n",
    "        self.n_strategy = n_strategy\n",
    "        # threshold for each phase: in explain in which phase I am I select a different array of probabilities for the strategies\n",
    "        self.phase_thresholds = phase_thresholds\n",
    "        # probability for each strategy in each phase\n",
    "        self.strategy_probs = strategy_probs\n",
    "        \n",
    "    def mutate(ind):\n",
    "        global mutation_rate\n",
    "        ind = deepcopy(ind)\n",
    "        phase_thresholds = np.random.normal(ind.phase_thresholds, mutation_rate[0]).tolist()\n",
    "        strategy_probs = np.random.normal(ind.strategy_probs, mutation_rate[1]).tolist()\n",
    "        return Individual(strategy_probs = strategy_probs, phase_thresholds = phase_thresholds, n_strategy = ind.n_strategy)\n",
    "\n",
    "    def __call__(self, state: Nim) -> Nimply:\n",
    "        # compute the phase ratio: it is a value between 0 and 1 that explain in which phase I am\n",
    "        phase_ratio = moves_ratio(state)\n",
    "        # phase index: 0 = start, 1 = mid, 2 = end\n",
    "        phase_index = (\n",
    "            0\n",
    "            if phase_ratio < self.phase_thresholds[0]\n",
    "            else (1 if self.phase_thresholds[0] <= phase_ratio <= self.phase_thresholds[1] else 2)\n",
    "        )\n",
    "        # select probs strategy based on phase\n",
    "        probs = self.strategy_probs[phase_index]\n",
    "        # select the most probable strategy based on probs\n",
    "        strategy = np.random.choice(STRATEGIES, p = softmax(probs))\n",
    "        return strategy(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(nim: Nim, strategy) -> int:\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player\n",
    "    return player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPPONENT = pure_random\n",
    "N_MATCHES = 100\n",
    "\n",
    "def evaluate_games(player_strategy, n: int = N_MATCHES, opponent=OPPONENT) -> float: \n",
    "    wins = 0\n",
    "    for _ in range(n):\n",
    "        random_size = random.randint(4, 10)\n",
    "        nim = Nim(random_size)\n",
    "        wins += 1 if match(nim, (player_strategy, opponent)) == 0 else 0\n",
    "    return wins / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 20\n",
    "\n",
    "def evolutionary_algorithm():\n",
    "    parent = Individual()\n",
    "    parent_result = evaluate_games(parent)\n",
    "    mutation_rate: float = (0.01, 0.1)\n",
    "\n",
    "    pbar = tqdm(range(0, 10_000 // LAMBDA))\n",
    "    for i in pbar:\n",
    "        pbar.set_description(f\"Parent Win-rate: {parent_result:.2%}\")\n",
    "        # generate offspring\n",
    "        offspring = [parent.mutate() for _ in range(LAMBDA)]\n",
    "        # evaluate offspring\n",
    "        results = [evaluate_games(i) for i in offspring]\n",
    "        # compute mutation rate: if you won more than 1/5 of the matches, increase the mutation rate, otherwise decrease it\n",
    "        incr_rate = np.sum([res > parent_result for res in results]) / LAMBDA\n",
    "        if incr_rate > 1 / 5:\n",
    "            mutation_rate = (mutation_rate[0] * 1.1, mutation_rate[1] * 1.1)\n",
    "        elif incr_rate < 1 / 5:\n",
    "            mutation_rate = (mutation_rate[0] / 1.1, mutation_rate[1] / 1.1)\n",
    "        # select the best offspring\n",
    "        solution_ind = np.argmax(results)\n",
    "        if parent_result < results[solution_ind]:\n",
    "            parent = offspring[solution_ind]\n",
    "            parent_result = results[solution_ind]\n",
    "        # stop if the parent won more than 95% of the matches\n",
    "        if parent_result >= 0.95:\n",
    "            break\n",
    "    return mutation_rate, parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ES 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent Win-rate: 37.00%:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent Win-rate: 63.00%: 100%|██████████| 500/500 [04:54<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "STRATEGIES = [lowest_available, greedy_move, gabriele]\n",
    "\n",
    "mutation_rate, parent = evolutionary_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4346850623387736e-23, 2.4346850623387733e-22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutation_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.37744994992950126, 0.7073826828688689]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresholds for each phase\n",
    "\n",
    "parent.phase_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43459519, 0.34129024, 0.22411457],\n",
       "       [0.24009752, 0.2731392 , 0.48676328],\n",
       "       [0.28828758, 0.28379908, 0.42791334]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the probability of each method in each phase\n",
    "\n",
    "softmax(parent.strategy_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES vs random:  0.41\n",
      "ES vs gabriele:  0.69\n",
      "ES vs optimal:  0.33\n"
     ]
    }
   ],
   "source": [
    "print(\"ES vs random: \", evaluate_games(parent, 100, pure_random))\n",
    "print(\"ES vs gabriele: \", evaluate_games(parent, 100, gabriele))\n",
    "print(\"ES vs optimal: \", evaluate_games(parent, 100, optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ES 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent Win-rate: 75.00%: 100%|██████████| 500/500 [1:15:56<00:00,  9.11s/it]\n"
     ]
    }
   ],
   "source": [
    "STRATEGIES = [lowest_available, greedy_move, optimal]\n",
    "\n",
    "mutation_rate, parent = evolutionary_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4346850623387736e-23, 2.4346850623387733e-22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutation_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08677210664706843, 0.831722787353731]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresholds for each phase\n",
    "\n",
    "parent.phase_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43817909, 0.34616131, 0.2156596 ],\n",
       "       [0.41725588, 0.25573407, 0.32701005],\n",
       "       [0.16714483, 0.30020808, 0.53264709]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the probability of each method in each phase\n",
    "\n",
    "softmax(parent.strategy_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES vs random:  0.63\n",
      "ES vs gabriele:  0.71\n",
      "ES vs optimal:  0.42\n"
     ]
    }
   ],
   "source": [
    "print(\"ES vs random: \", evaluate_games(parent, 100, pure_random))\n",
    "print(\"ES vs gabriele: \", evaluate_games(parent, 100, gabriele))\n",
    "print(\"ES vs optimal: \", evaluate_games(parent, 100, optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ES 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent Win-rate: 84.00%: 100%|██████████| 500/500 [54:48<00:00,  6.58s/it]\n"
     ]
    }
   ],
   "source": [
    "STRATEGIES = [lowest_available, greedy_move, expert_system]\n",
    "\n",
    "mutation_rate, parent = evolutionary_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4346850623387736e-23, 2.4346850623387733e-22)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutation_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.483551884760844, 0.7352287536073697]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresholds for each phase\n",
    "\n",
    "parent.phase_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27359103, 0.35138813, 0.37502084],\n",
       "       [0.28554353, 0.44493595, 0.26952052],\n",
       "       [0.43137673, 0.23991707, 0.3287062 ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the probability of each method in each phase\n",
    "\n",
    "softmax(parent.strategy_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES vs random:  0.65\n",
      "ES vs gabriele:  0.71\n",
      "ES vs optimal:  0.54\n"
     ]
    }
   ],
   "source": [
    "print(\"ES vs random: \", evaluate_games(parent, 100, pure_random))\n",
    "print(\"ES vs gabriele: \", evaluate_games(parent, 100, gabriele))\n",
    "print(\"ES vs optimal: \", evaluate_games(parent, 100, optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MonteCarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MonteCarlo strategy, the principle followed is as follows: \n",
    "\n",
    "Whenever a move is to be made by our player, the latter copies the current board state, and simulates num_matches on the latter. Particularly in simulated games, both players make random moves. For each simulated game, the first move is taken and an evaluation is made as to whether that game is a winner or not. Then the win_ratio is calculated for each available first move made, and the first move that resulted in the most wins is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MATCHES = 1000\n",
    "NIM_SIZE = 5\n",
    "N_GAMES_SIMULATED_PER_MOVE = 100\n",
    "\n",
    "nim = Nim(NIM_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_possible_moves(state: Nim) -> list:\n",
    "    return [Nimply(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "\n",
    "def max_num_objects(state: Nim) -> dict:\n",
    "    return {r: c for r, c in enumerate(state.rows)}\n",
    "\n",
    "def sample_random_move(state: Nim) -> Nimply:\n",
    "    possible_moves = generate_all_possible_moves(state)\n",
    "    move = random.choice(range(len(possible_moves)))\n",
    "    return possible_moves[move], move\n",
    "\n",
    "def sampler(state: Nim) -> Nimply:\n",
    "    return sample_random_move(state=state)[0]\n",
    "\n",
    "def generate_game(state: Nim) -> tuple:\n",
    "    strategy = (sampler, pure_random)\n",
    "    temp_state = deepcopy(state)\n",
    "    first_move = None \n",
    "    player = 0 \n",
    "    while temp_state:\n",
    "        ply = strategy[player](temp_state)\n",
    "        first_move = ply if first_move is None else first_move\n",
    "        temp_state.nimming(ply)\n",
    "        player = 1 - player\n",
    "    return (first_move, player)\n",
    "\n",
    "def generate_games(state: Nim, n: int = 1000) -> list:\n",
    "    return [generate_game(state=state) for _ in range(n)]\n",
    "\n",
    "# function to choose the best move using MonteCarlo method, as it is possible to see, for each move this function is called \n",
    "# and it generates N_GAMES_SIMULATED_PER_MOVE games, then it counts the number of games won by each move and it chooses the\n",
    "# move with the highest winrate\n",
    "\n",
    "def choose_best_move(state: Nim, n_games: int = 1000) -> Nimply:\n",
    "    games = generate_games(state=state, n=n_games)\n",
    "    winning_moves = np.array([game[0] for game in games if game[1] == 0])\n",
    "    total_moves = np.array([game[0] for game in games])\n",
    "    winning_moves, winning_count = np.unique(winning_moves, return_counts=True, axis=0)\n",
    "    total_moves, total_count = np.unique(total_moves, return_counts=True, axis=0)\n",
    "\n",
    "    best_move_val = -1 \n",
    "    best_move_index = -1\n",
    "\n",
    "    for i, move in enumerate(total_moves):\n",
    "        for j, move2 in enumerate(winning_moves):\n",
    "            if (move == move2).all():\n",
    "                winrate = winning_count[j]/total_count[i]\n",
    "                if winrate > best_move_val:\n",
    "                    best_move_val = winrate\n",
    "                    best_move_index = i\n",
    "                break \n",
    "    \n",
    "    best_move = total_moves[best_move_index]\n",
    "\n",
    "    return Nimply(best_move[0], best_move[1])\n",
    "\n",
    "def our_strategy(state: Nim) -> Nimply:\n",
    "    return choose_best_move(state=state, n_games=N_GAMES_SIMULATED_PER_MOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of the selected moves over 1000 random games \n",
    "\n",
    "def plot_hist_moves(state: Nim) -> Nimply:\n",
    "    list = []\n",
    "    for i in range(1000):\n",
    "        _, num = sample_random_move(state=state)\n",
    "        list.append(num)\n",
    "\n",
    "    plt.hist(list, bins=state.n_possible_moves(), range=(0,state.n_possible_moves())) \n",
    "    plt.show()\n",
    "\n",
    "plot_hist_moves(nim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between our solution and the ones provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(strategy1, strategy2):\n",
    "    \"\"\"evaluate put a first strategy versus a second one for a certain number of times, the results is the ratio \n",
    "    between the won matches and the total number of played matches\"\"\"\n",
    "    players = (strategy1, strategy2)\n",
    "    won = 0\n",
    "\n",
    "    for _ in tqdm(range(NUM_MATCHES)):\n",
    "        nim = Nim(NIM_SIZE)\n",
    "        player = random.randint(0,1) # make a random start\n",
    "        while nim:\n",
    "            ply = players[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 0:\n",
    "            won += 1\n",
    "    return round(won / NUM_MATCHES, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Solution vs. Pure Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:31<00:00, 31.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Solution vs Opponent => 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ev_optimalvsexpert = evaluate(our_strategy, pure_random)\n",
    "print(f\"Our Solution vs Opponent => {ev_optimalvsexpert}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Solution vs. Gabriele's Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 39.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Solution vs Opponent => 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ev_optimalvsexpert = evaluate(our_strategy, gabriele)\n",
    "print(f\"Our Solution vs Opponent => {ev_optimalvsexpert}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Solution vs. Optimal Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:43<00:00, 23.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Solution vs Opponent => 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ev_optimalvsexpert = evaluate(our_strategy, optimal)\n",
    "print(f\"Our Solution vs Opponent => {ev_optimalvsexpert}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Strategies vs. MonteCarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_probs_parent1 = np.array([[0.43459519, 0.34129024, 0.22411457], [0.24009752, 0.2731392 , 0.48676328], [0.28828758, 0.28379908, 0.42791334]])\n",
    "phase_thresholds_parent1 = [0.37744994992950126, 0.7073826828688689]\n",
    "parent1 = Individual(strategy_probs= strategy_probs_parent1, phase_thresholds=phase_thresholds_parent1)\n",
    "\n",
    "strategy_probs_parent2 = np.array([[0.43817909, 0.34616131, 0.2156596 ], [0.41725588, 0.25573407, 0.32701005], [0.16714483, 0.30020808, 0.53264709]])\n",
    "phase_thresholds_parent2 = [0.08677210664706843, 0.831722787353731]\n",
    "parent2 = Individual(strategy_probs= strategy_probs_parent2, phase_thresholds=phase_thresholds_parent2)\n",
    "\n",
    "strategy_probs_parent3 = np.array([[0.27359103, 0.35138813, 0.37502084], [0.28554353, 0.44493595, 0.26952052], [0.43137673, 0.23991707, 0.3287062 ]])\n",
    "phase_thresholds_parent3 = [0.483551884760844, 0.7352287536073697]\n",
    "parent3 = Individual(strategy_probs= strategy_probs_parent3, phase_thresholds=phase_thresholds_parent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES1 vs MonteCarlo:  0.05\n",
      "ES2 vs MonteCarlo:  0.06\n",
      "ES3 vs MonteCarlo:  0.15\n"
     ]
    }
   ],
   "source": [
    "print(\"ES1 vs MonteCarlo: \", evaluate_games(parent1, 100, our_strategy))\n",
    "print(\"ES2 vs MonteCarlo: \", evaluate_games(parent2, 100, our_strategy))\n",
    "print(\"ES3 vs MonteCarlo: \", evaluate_games(parent3, 100, our_strategy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
